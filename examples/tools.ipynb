{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def mprint(val: str):\n",
    "    display(Markdown(val))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DuckDuckGo Web-Search\n",
    "\n",
    "The following is an example of using DuckDuckGo to perform a web search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'What are LLMs, and how are they used in generative AI?',\n",
       "  'href': 'https://www.computerworld.com/article/3697649/what-are-large-language-models-and-how-are-they-used-in-generative-ai.html',\n",
       "  'body': \"Large language models are the algorithmic basis for chatbots like OpenAI's ChatGPT and Google's Bard. The technology is tied back to billions — even trillions — of parameters that can make them...\"},\n",
       " {'title': 'What is a large language model and how does it work? - Fast Company',\n",
       "  'href': 'https://www.fastcompany.com/90884581/what-is-a-large-language-model',\n",
       "  'body': 'Large language models are the foundational technology behind recent artificial intelligence advancements like ChatGPT.'},\n",
       " {'title': 'Introduction to Large Language Models - Baeldung',\n",
       "  'href': 'https://www.baeldung.com/cs/large-language-models',\n",
       "  'body': 'A quick and practical guide to Large Language Models. Natural Language Processing (NLP), is an interdisciplinary subfield of linguistics, computer science, and artificial intelligence.Its goal is for a computer to be able to understand texts and other media in their natural languages, including their contextual nuances.'}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llm_chain.tools import DuckDuckGoSearch\n",
    "\n",
    "duckduckgo_search = DuckDuckGoSearch(top_n=3)\n",
    "duckduckgo_search(\"What is a large language model?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `duckduckgo_search` object has a `history` property that allows us to view the searches performed: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a large language model?\n",
      "[{'body': 'Large language models are the algorithmic basis for chatbots like '\n",
      "          \"OpenAI's ChatGPT and Google's Bard. The technology is tied back to \"\n",
      "          'billions — even trillions — of parameters that can make them...',\n",
      "  'href': 'https://www.computerworld.com/article/3697649/what-are-large-language-models-and-how-are-they-used-in-generative-ai.html',\n",
      "  'title': 'What are LLMs, and how are they used in generative AI?'},\n",
      " {'body': 'Large language models are the foundational technology behind recent '\n",
      "          'artificial intelligence advancements like ChatGPT.',\n",
      "  'href': 'https://www.fastcompany.com/90884581/what-is-a-large-language-model',\n",
      "  'title': 'What is a large language model and how does it work? - Fast '\n",
      "           'Company'},\n",
      " {'body': 'A quick and practical guide to Large Language Models. Natural '\n",
      "          'Language Processing (NLP), is an interdisciplinary subfield of '\n",
      "          'linguistics, computer science, and artificial intelligence.Its goal '\n",
      "          'is for a computer to be able to understand texts and other media in '\n",
      "          'their natural languages, including their contextual nuances.',\n",
      "  'href': 'https://www.baeldung.com/cs/large-language-models',\n",
      "  'title': 'Introduction to Large Language Models - Baeldung'}]\n"
     ]
    }
   ],
   "source": [
    "print(duckduckgo_search.history[0].query)\n",
    "pprint(duckduckgo_search.history[0].results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping a URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Example Domain\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "Example Domain\n",
       "This domain is for use in illustrative examples in documents. You may use this\n",
       "    domain in literature without prior coordination or asking for permission.\n",
       "More information..."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from llm_chain.tools import scrape_url\n",
    "\n",
    "result = scrape_url(url='http://example.com')\n",
    "mprint(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Documents\n",
    "\n",
    "A `Document` object is a simple class that contains `content` and `metadata` properties.\n",
    "\n",
    "Sometimes we want to split a document up into multiple chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Pretend this is a long document that we want to split.' metadata={'id': 'some unique-id'}\n",
      "content='Pretend this is another long document that we want to split.' metadata={'id': 'another unique-id'}\n"
     ]
    }
   ],
   "source": [
    "from llm_chain.base import Document\n",
    "\n",
    "doc_a = Document(\n",
    "    content=\"Pretend this is a long document that we want to split.\",\n",
    "    metadata={'id': 'some unique-id'},\n",
    ")\n",
    "doc_b = Document(\n",
    "    content=\"Pretend this is another long document that we want to split.\",\n",
    "    metadata={'id': 'another unique-id'},\n",
    ")\n",
    "print(doc_a)\n",
    "print(doc_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(content='Pretend this is a', metadata={'id': 'some unique-id'}),\n",
       " Document(content='long document that', metadata={'id': 'some unique-id'}),\n",
       " Document(content='we want to split.', metadata={'id': 'some unique-id'}),\n",
       " Document(content='Pretend this is', metadata={'id': 'another unique-id'}),\n",
       " Document(content='another long', metadata={'id': 'another unique-id'}),\n",
       " Document(content='document that we', metadata={'id': 'another unique-id'}),\n",
       " Document(content='want to split.', metadata={'id': 'another unique-id'})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from llm_chain.tools import split_documents\n",
    "\n",
    "split_documents(docs=[doc_a, doc_b], max_chars=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
